{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.13.1\n",
    "# !pip install Sequential\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import sentiment_dataset as sentiment_dataset\n",
    "import sentiment_model_cnn as sentiment_model_cnn\n",
    "import config_holder as config_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Parameters\n",
    "num_epoch= 10\n",
    "config_file = json.load(open('training_config.json', \"r\"))\n",
    "bucket_location = 'ieor4577-hw6'\n",
    "key_train = \"train\"\n",
    "key_dev = \"dev\"\n",
    "key_eval = \"eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for training...\n",
      "Fetching train data...\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/data/util/random_seed.py:58: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/yujiawang/Documents/IEOR 4577 AI & OR in the Cloud/Assignments/Assignment 6/model training cloud/sentiment_dataset.py:76: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "Fetching validation data...\n",
      "Fetching eval data...\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From //anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Starting training...\n",
      "Epoch 1/10\n",
      "13600/13600 [==============================] - 180s 13ms/step - loss: 0.4391 - acc: 0.7934 - val_loss: 0.4144 - val_acc: 0.8084\n",
      "Epoch 2/10\n",
      "13600/13600 [==============================] - 152s 11ms/step - loss: 0.4020 - acc: 0.8156 - val_loss: 0.4100 - val_acc: 0.8098\n",
      "Epoch 3/10\n",
      "13600/13600 [==============================] - 163s 12ms/step - loss: 0.3862 - acc: 0.8245 - val_loss: 0.4034 - val_acc: 0.8137\n",
      "Epoch 4/10\n",
      "13600/13600 [==============================] - 164s 12ms/step - loss: 0.3734 - acc: 0.8318 - val_loss: 0.4038 - val_acc: 0.8153\n",
      "Epoch 5/10\n",
      "13600/13600 [==============================] - 194s 14ms/step - loss: 0.3623 - acc: 0.8378 - val_loss: 0.4053 - val_acc: 0.8152\n",
      "Epoch 6/10\n",
      "13600/13600 [==============================] - 157s 12ms/step - loss: 0.3514 - acc: 0.8439 - val_loss: 0.4147 - val_acc: 0.8137\n",
      "Epoch 7/10\n",
      "13600/13600 [==============================] - 168s 12ms/step - loss: 0.3414 - acc: 0.8491 - val_loss: 0.4157 - val_acc: 0.8132\n",
      "Epoch 8/10\n",
      "13600/13600 [==============================] - 169s 12ms/step - loss: 0.3325 - acc: 0.8537 - val_loss: 0.4282 - val_acc: 0.8079\n",
      "Epoch 9/10\n",
      "13600/13600 [==============================] - 163s 12ms/step - loss: 0.3237 - acc: 0.8583 - val_loss: 0.4329 - val_acc: 0.8099\n",
      "Epoch 10/10\n",
      "13600/13600 [==============================] - 167s 12ms/step - loss: 0.3158 - acc: 0.8622 - val_loss: 0.4445 - val_acc: 0.8086\n",
      "Test loss:0.443156729452312\n",
      "Test accuracy:0.8082749843597412\n"
     ]
    }
   ],
   "source": [
    "# Train CNN Model\n",
    "print(\"Preparing for training...\")\n",
    "\n",
    "training_config = config_file\n",
    "\n",
    "training_config[\"num_epoch\"] = num_epoch\n",
    "\n",
    "train_dataset = sentiment_dataset.train_input_fn(bucket_location, key_train, training_config)\n",
    "validation_dataset = sentiment_dataset.validation_input_fn(bucket_location, key_dev, training_config)\n",
    "eval_dataset = sentiment_dataset.eval_input_fn(bucket_location, key_eval, training_config)\n",
    "\n",
    "model = sentiment_model_cnn.keras_model_fn(None, training_config)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "validation_dataset[1]\n",
    "model.fit(\n",
    "    x=train_dataset[0], y=train_dataset[1], steps_per_epoch=train_dataset[2][\"num_batches\"],\n",
    "    epochs=training_config[\"num_epoch\"],\n",
    "    validation_data=(validation_dataset[0], validation_dataset[1]),\n",
    "    validation_steps=int(validation_dataset[2][\"num_batches\"]))\n",
    "\n",
    "score = model.evaluate(eval_dataset[0], eval_dataset[1], steps=eval_dataset[2][\"num_batches\"], verbose=0)\n",
    "\n",
    "print(\"Test loss:{}\".format(score[0]))\n",
    "print(\"Test accuracy:{}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d37d9d8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d37d9d8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d37d9d8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d37d9d8>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x63d37d9d8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function canonicalize_signatures.<locals>.signature_wrapper at 0x63d37d9d8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function canonicalize_signatures.<locals>.signature_wrapper at 0x63d37d9d8> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function canonicalize_signatures.<locals>.signature_wrapper at 0x63d37d9d8>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d3660d0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d3660d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d3660d0> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x63d3660d0>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "INFO:tensorflow:Assets written to: sentiment_model.h5/1/assets\n",
      "Model successfully saved\n"
     ]
    }
   ],
   "source": [
    "# Save Trained Model\n",
    "import boto3\n",
    "\n",
    "tf.saved_model.save(model, \"sentiment_model.h5/1\")\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id='AKIAJYIZS65GX5JHCR6Q',\n",
    "    aws_secret_access_key='AKIAJYIZS65GX5JHCR6Q')\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_object(Bucket=\"ieor4577-hw6\", Key=(\"sentiment_model.h5/1/assets\"+'/'))\n",
    "s3.put_object(Bucket=\"ieor4577-hw6\", Key=(\"sentiment_model.h5/1/variables\"+'/'))\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/saved_model.pb', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/saved_model.pb')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/variables/variables.data-00000-of-00002', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/variables/variables.data-00000-of-00002')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/variables/variables.data-00001-of-00002', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/variables/variables.data-00001-of-00002')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/variables/variables.index', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/variables/variables.index')\n",
    "\n",
    "print(\"Model successfully saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
