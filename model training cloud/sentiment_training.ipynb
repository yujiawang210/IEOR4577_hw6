{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "# print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.13.1\n",
    "# !pip install Sequential\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from tensorflow import keras \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import sentiment_dataset as sentiment_dataset\n",
    "import sentiment_model_cnn as sentiment_model_cnn\n",
    "import config_holder as config_holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Parameters\n",
    "num_epoch= 10\n",
    "config_file = json.load(open('training_config.json', \"r\"))\n",
    "bucket_location = 'ieor4577-hw6'\n",
    "key_train = \"train\"\n",
    "key_dev = \"dev\"\n",
    "key_eval = \"eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for training...\n",
      "Fetching train data...\n",
      "Fetching validation data...\n",
      "Fetching eval data...\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Starting training...\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/10\n",
      "13600/13600 [==============================] - 362s 27ms/step - loss: 0.4373 - acc: 0.7944 - val_loss: 0.4124 - val_acc: 0.8091\n",
      "Epoch 2/10\n",
      "13600/13600 [==============================] - 360s 26ms/step - loss: 0.4012 - acc: 0.8159 - val_loss: 0.4084 - val_acc: 0.8114\n",
      "Epoch 3/10\n",
      "13600/13600 [==============================] - 356s 26ms/step - loss: 0.3856 - acc: 0.8248 - val_loss: 0.4042 - val_acc: 0.8139\n",
      "Epoch 4/10\n",
      "13600/13600 [==============================] - 359s 26ms/step - loss: 0.3729 - acc: 0.8319 - val_loss: 0.4039 - val_acc: 0.8154\n",
      "Epoch 5/10\n",
      "13600/13600 [==============================] - 358s 26ms/step - loss: 0.3619 - acc: 0.8385 - val_loss: 0.4046 - val_acc: 0.8150\n",
      "Epoch 6/10\n",
      "13600/13600 [==============================] - 360s 26ms/step - loss: 0.3513 - acc: 0.8440 - val_loss: 0.4187 - val_acc: 0.8113\n",
      "Epoch 7/10\n",
      "13600/13600 [==============================] - 358s 26ms/step - loss: 0.3415 - acc: 0.8494 - val_loss: 0.4139 - val_acc: 0.8127\n",
      "Epoch 8/10\n",
      "13600/13600 [==============================] - 365s 27ms/step - loss: 0.3325 - acc: 0.8542 - val_loss: 0.4283 - val_acc: 0.8088\n",
      "Epoch 9/10\n",
      "13600/13600 [==============================] - 362s 27ms/step - loss: 0.3239 - acc: 0.8582 - val_loss: 0.4347 - val_acc: 0.8092\n",
      "Epoch 10/10\n",
      "13600/13600 [==============================] - 361s 27ms/step - loss: 0.3161 - acc: 0.8622 - val_loss: 0.4437 - val_acc: 0.8094\n",
      "Test loss:0.44066505240276455\n",
      "Test accuracy:0.8109375238418579\n"
     ]
    }
   ],
   "source": [
    "# Train CNN Model\n",
    "print(\"Preparing for training...\")\n",
    "\n",
    "training_config = config_file\n",
    "\n",
    "training_config[\"num_epoch\"] = num_epoch\n",
    "\n",
    "train_dataset = sentiment_dataset.train_input_fn(bucket_location, key_train, training_config)\n",
    "validation_dataset = sentiment_dataset.validation_input_fn(bucket_location, key_dev, training_config)\n",
    "eval_dataset = sentiment_dataset.eval_input_fn(bucket_location, key_eval, training_config)\n",
    "\n",
    "model = sentiment_model_cnn.keras_model_fn(None, training_config)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "validation_dataset[1]\n",
    "model.fit(\n",
    "    x=train_dataset[0], y=train_dataset[1], steps_per_epoch=train_dataset[2][\"num_batches\"],\n",
    "    epochs=training_config[\"num_epoch\"],\n",
    "    validation_data=(validation_dataset[0], validation_dataset[1]),\n",
    "    validation_steps=int(validation_dataset[2][\"num_batches\"]))\n",
    "\n",
    "score = model.evaluate(eval_dataset[0], eval_dataset[1], steps=eval_dataset[2][\"num_batches\"], verbose=0)\n",
    "\n",
    "print(\"Test loss:{}\".format(score[0]))\n",
    "print(\"Test accuracy:{}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x7f7e11e61438>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "WARNING:tensorflow:Model was compiled with an optimizer, but the optimizer is not from `tf.train` (e.g. `tf.train.AdagradOptimizer`). Only the serving graph was exported. The train and evaluate graphs were not added to the SavedModel.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: sentiment_model.h5/1583604702/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'sentiment_model.h5/1583604702'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Trained Model\n",
    "tf.contrib.saved_model.save_keras_model(model, \"sentiment_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved\n"
     ]
    }
   ],
   "source": [
    "# Save Results to S3\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "s3.put_object(Bucket=\"ieor4577-hw6\", Key=(\"sentiment_model.h5/1/assets\"+'/'))\n",
    "s3.put_object(Bucket=\"ieor4577-hw6\", Key=(\"sentiment_model.h5/1/variables\"+'/'))\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/saved_model.pb', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/saved_model.pb')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/assets/saved_model.json', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/assets/saved_model.json')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/variables/checkpoint', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/variables/checkpoint')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/variables/variables.data-00000-of-00001', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/variables/variables.data-00000-of-00001')\n",
    "s3.meta.client.upload_file('sentiment_model.h5/1/variables/variables.index', \n",
    "                           'ieor4577-hw6', \n",
    "                           'sentiment_model.h5/1/variables/variables.index')\n",
    "\n",
    "print(\"Model successfully saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
